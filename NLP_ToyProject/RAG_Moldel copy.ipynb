{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 및 API key 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from openai import OpenAI\n",
    "from serpapi import GoogleSearch \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "from langchain_anthropic import ChatAnthropic, AnthropicLLM\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "from langchain.memory import SimpleMemory\n",
    "from datetime import datetime\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import json\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrap_openai(openai.Client())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 및 SerpAPI 키 설정\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERP_API_KEY = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# FAISS 인덱스 저장 경로\n",
    "FAISS_INDEX_PATH = Path('local/news-please/faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DPR 기반 사내 뉴스 검색 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPR():\n",
    "    def __init__(self):\n",
    "        \"\"\"사내 뉴스 데이터베이스를 로드하고 FAISS 인덱스를 활용한 검색을 수행하는 DPR 클래스\"\"\"\n",
    "        self.ds = datasets.load_dataset('sanxing/advfake_news_please')['train']\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.index_dpr()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def index_dpr(self):\n",
    "        \"\"\"DPR 기반 뉴스 임베딩을 생성하고 FAISS 인덱스를 구축\"\"\"\n",
    "        from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "        faiss_path = FAISS_INDEX_PATH / 'my_index.faiss'\n",
    "        if faiss_path.exists():\n",
    "            print('🔹 FAISS 인덱스 로드 중...')\n",
    "            self.ds.load_faiss_index('embeddings', str(faiss_path))\n",
    "            return\n",
    "\n",
    "        print('🔹 FAISS 인덱스 생성 중...')\n",
    "        ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(self.device)\n",
    "        ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "        # 🔹 뉴스 제목을 임베딩 벡터로 변환하여 저장\n",
    "        ds_with_embeddings = self.ds.map(lambda example: {\n",
    "            'embeddings': ctx_encoder(**ctx_tokenizer(example[\"title\"], return_tensors=\"pt\", padding=True).to(self.device))[0].cpu().numpy()\n",
    "        }, batched=True, batch_size=64)\n",
    "\n",
    "        ds_with_embeddings.add_faiss_index(column='embeddings')\n",
    "\n",
    "        print('🔹 FAISS 인덱스 저장 중...')\n",
    "        ds_with_embeddings.save_faiss_index('embeddings', str(faiss_path))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, query):\n",
    "        \"\"\"입력된 쿼리를 기반으로 가장 관련성 높은 뉴스 10개 검색\"\"\"\n",
    "        from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "\n",
    "        q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(self.device)\n",
    "        q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "        # 🔹 입력 쿼리를 DPR 임베딩으로 변환\n",
    "        question_embedding = q_encoder(**q_tokenizer(query, return_tensors=\"pt\").to(self.device))[0][0].cpu().numpy()\n",
    "        \n",
    "        # 🔹 FAISS 검색 수행\n",
    "        scores, retrieved_examples = self.ds.get_nearest_examples('embeddings', question_embedding, k=5)\n",
    "\n",
    "        # 🔹 결과를 딕셔너리 리스트 형태로 변환\n",
    "        retrieved_examples = [dict(zip(retrieved_examples, t)) for t in zip(*retrieved_examples.values())]\n",
    "\n",
    "        return scores, retrieved_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer,\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    ")\n",
    "\n",
    "FAISS_INDEX_PATH = Path(\"faiss_index\")  # 저장할 폴더\n",
    "DATASET_SAVE_PATH = Path(\"news_dataset\")  # 데이터셋 저장 위치\n",
    "FAISS_FILE = FAISS_INDEX_PATH / \"my_index.faiss\"\n",
    "\n",
    "class DPR():\n",
    "    def __init__(self):\n",
    "        \"\"\"사내 뉴스 데이터베이스를 로드하고 FAISS 인덱스를 활용한 검색을 수행하는 DPR 클래스\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # 🔹 저장된 데이터셋이 있으면 로드, 없으면 새로 다운로드\n",
    "        if DATASET_SAVE_PATH.exists():\n",
    "            print(\"🔹 저장된 데이터셋 로드 중...\")\n",
    "            self.ds = datasets.load_from_disk(str(DATASET_SAVE_PATH))\n",
    "        else:\n",
    "            print(\"🔹 새로운 데이터셋 다운로드 중...\")\n",
    "            self.ds = datasets.load_dataset('sanxing/advfake_news_please')['train']\n",
    "            self.ds.save_to_disk(str(DATASET_SAVE_PATH))  # 저장\n",
    "\n",
    "        # FAISS 인덱싱\n",
    "        self.index_dpr()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def index_dpr(self):\n",
    "        \"\"\"DPR 기반 뉴스 임베딩을 생성하고 FAISS 인덱스를 구축\"\"\"\n",
    "        if FAISS_FILE.exists():\n",
    "            print('🔹 FAISS 인덱스 로드 중...')\n",
    "            self.ds.load_faiss_index('embeddings', str(FAISS_FILE))\n",
    "            return\n",
    "\n",
    "        print('🔹 FAISS 인덱스 생성 중...')\n",
    "        ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(self.device)\n",
    "        ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "        def embed_batch(examples):\n",
    "            inputs = ctx_tokenizer(examples[\"title\"], return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "            embeddings = ctx_encoder(**inputs).pooler_output.cpu().numpy()\n",
    "            return {\"embeddings\": embeddings}\n",
    "\n",
    "        ds_with_embeddings = self.ds.map(embed_batch, batched=True, batch_size=64)\n",
    "        ds_with_embeddings.add_faiss_index(column='embeddings')\n",
    "\n",
    "        print('🔹 FAISS 인덱스 저장 중...')\n",
    "        FAISS_INDEX_PATH.mkdir(parents=True, exist_ok=True)\n",
    "        ds_with_embeddings.save_faiss_index('embeddings', str(FAISS_FILE))\n",
    "\n",
    "        # 🔹 데이터셋도 함께 저장\n",
    "        ds_with_embeddings.save_to_disk(str(DATASET_SAVE_PATH))\n",
    "        self.ds = ds_with_embeddings  # 메모리에 저장\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, query):\n",
    "        \"\"\"입력된 쿼리를 기반으로 가장 관련성 높은 뉴스 5개 검색\"\"\"\n",
    "        q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(self.device)\n",
    "        q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "        # 🔹 입력 쿼리를 DPR 임베딩으로 변환\n",
    "        inputs = q_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "        question_embedding = q_encoder(**inputs).pooler_output.cpu().numpy()[0]\n",
    "\n",
    "        # 🔹 FAISS 검색 수행\n",
    "        scores, retrieved_examples = self.ds.get_nearest_examples('embeddings', question_embedding, k=5)\n",
    "\n",
    "        # 🔹 결과를 딕셔너리 리스트 형태로 변환\n",
    "        retrieved_examples = [dict(zip(retrieved_examples, t)) for t in zip(*retrieved_examples.values())]\n",
    "\n",
    "        return scores, retrieved_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (1.10.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch datasets faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Google SerpAPI 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_serpapi(q):\n",
    "    \"\"\"Google SerpAPI를 사용하여 실시간 뉴스 검색\"\"\"\n",
    "    params = {\n",
    "        \"api_key\": SERP_API_KEY,  # SerpAPI 키\n",
    "        \"engine\": \"google\",  # Google 검색 엔진 사용\n",
    "        \"q\": q,  # 검색어\n",
    "        \"location\": \"Austin, Texas, United States\",  # 검색 지역 지정\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"gl\": \"us\",  # 국가 설정 (미국)\n",
    "        \"hl\": \"en\",  # 언어 설정 (영어)\n",
    "        \"num\": \"30\"  # 검색 결과 최대 30개 가져오기\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)  # SerpAPI를 사용한 Google 검색 객체 생성\n",
    "    results = search.get_dict()  # JSON 형식으로 검색 결과 가져오기\n",
    "    return results  # 결과 반환\n",
    "\n",
    "def concat_snippets(organic_results):\n",
    "    \"\"\"검색된 기사에서 유의미한 정보를 필터링하고 요약\"\"\"\n",
    "    organic_results = [result for result in organic_results if 'snippet' in result]  # snippet이 있는 기사만 필터링\n",
    "    organic_results = [result for result in organic_results if 'NBC' not in result['source'] and 'NBC' not in result['title']]  # NBC 뉴스 제외\n",
    "    organic_results = [result for result in organic_results if 'fact' not in result['link']]  # 'fact'가 포함된 링크 제외 (팩트체크 기사 필터링)\n",
    "    organic_results = organic_results[:5]  # 상위 5개 기사만 선택\n",
    "\n",
    "    return '\\n'.join([\n",
    "        f'Title: {result[\"title\"]}\\nSource: {result[\"source\"]}, {result[\"date\"] if \"date\" in result else \"\"}\\nContent: {result[\"snippet\"]}' \n",
    "        for result in organic_results\n",
    "    ])\n",
    "\n",
    "def get_google_ctx(q):\n",
    "    \"\"\"실시간 검색 결과를 LLM 입력에 사용할 형태로 변환\"\"\"\n",
    "    search_results = search_serpapi(q)  # Google 검색 실행\n",
    "    if 'organic_results' in search_results:\n",
    "        return concat_snippets(search_results['organic_results'])  # 검색 결과 정리 후 반환\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_news(news_headline):\n",
    "    \"\"\"사내 뉴스 및 Google 검색을 결합하여 관련 뉴스 검색\"\"\"\n",
    "    #dpr = DPR()\n",
    "    #_, retrieved_news = dpr.search(news_headline)\n",
    "    retrieved_news=[]\n",
    "    print(f\"retrieved_news:{retrieved_news}\")\n",
    "    google_results = get_google_ctx(news_headline)\n",
    "    print(google_results)\n",
    "    \n",
    "    return retrieved_news + [google_results]\n",
    "\n",
    "def get_plausibility_score(news_text, retrieved_news):\n",
    "    \"\"\"GPT-4o를 이용하여 뉴스의 개연성 점수 예측\"\"\"\n",
    "    input_data = {\"news_text\":news_text, \"retrieved_news\" : retrieved_news}\n",
    "    result = chain_1.invoke(input_data)\n",
    "    print(result)\n",
    "    return result['plausibility_score']\n",
    "\n",
    "\n",
    "def generate_final_score(news_text, retrieved_news):\n",
    "    \"\"\"샘플링을 통해 최종 개연성 점수 생성 (0~1 범위)\"\"\"\n",
    "    scores = [get_plausibility_score(news_text, retrieved_news)['plausibility_score'] for _ in range(3)]\n",
    "    scores = list(map(int, scores))\n",
    "    final_score = sum(scores) / len(scores)\n",
    "    return final_score / 10  # 0~1 범위로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의학과학개요 검토 LLM\n",
    "llm1 = ChatOpenAI(temperature=1,               # 창의성 (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # 최대 토큰수\n",
    "                 model_name='gpt-4o',  # 모델명\n",
    "                )\n",
    "\n",
    "llm2 = ChatAnthropic(model='claude-3-5-sonnet-20240620',max_tokens=8192)\n",
    "\n",
    "\n",
    "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 출력 형식 지시사항을 파싱\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"plausibility_score\",\n",
    "        description=\"A numerical score between 1 and 10 that represents how plausible the given statement is. \"\n",
    "                    \"1 means 'completely false', while 10 means 'fully plausible'.\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"reason\",\n",
    "        description=\"A textual explanation providing the reasoning behind the assigned plausibility score.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt_template_1 = \"\"\"\n",
    "\n",
    "    Today is March 26, 2024. You predict the plausibility of a news you haven’t seen.\n",
    "\n",
    "    News: \"{news_text}\"\n",
    "\n",
    "    Retrieved News:\n",
    "    {retrieved_news}\n",
    "\n",
    "    Based on the provided information, rate the plausibility of the news on a scale of 1 to 10 (1: completely false, 10: fully plausible). Also, give the proper reason.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=prompt_template_1,\n",
    "    input_variables=[\"news_text\",\"retrieved news\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | llm2 | output_parser  # 프롬프트, 모델, 출력 파서를 연결\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_news:[]\n",
      "Title: 뉴스1\n",
      "Source: 뉴스1, \n",
      "Content: 윤석열 탄핵심판·이재명 선거법 2심 변론종결… · \"자백하고 사과\" vs \"정당성 부각\"…'尹 최후진술' 놓고도 시민사회 '쩍' · [탄핵심판의 얼굴들]④국무총리 한덕수…\n",
      "Title: CONNECT 서비스\n",
      "Source: 뉴스1, \n",
      "Content: 뉴스1, AFP 및 Reuter 뉴스정보 및 사진을 실시간으로 열람할 수 있는 서비스로, 24시간 국내외 속보를 한 눈에 접할 수 있습니다. 매체사,기업, 관공서, 개인 등 이용 ...\n",
      "Title: 뉴스1 (@News1Kr) / X\n",
      "Source: x.com, \n",
      "Content: 사실 앞에 겸손한 민영 통신 뉴스1입니다. 유튜브 : http://youtube.com/user/news1korea. Translate bio.\n",
      "Title: 뉴스 테스트\n",
      "Source: 나무위키, \n",
      "Content: 다양한 분야의 뉴스/시사 상식의 습득 수준을 객관적이고 체계적인 지표로 측정할 수 있도록 개발된 뉴스 상식 검정 시험이다. 2017년 3월 25일 시행된 1회 시험에서 최고 ...\n",
      "Title: Minuteman III test launch showcases readiness of US ...\n",
      "Source: Space Force (.mil), 4 days ago\n",
      "Content: Minuteman III test launch showcases readiness of US nuclear force's safe, effective deterrent. Published Feb. 19, 2025; By Staff Sgt. Joshua ...\n",
      "{'plausibility_score': '3', 'reason': \"The news '테스트 뉴스 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of '테스트 뉴스 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test entry rather than a real news item.\"}\n",
      "{'plausibility_score': '3', 'reason': \"The news '테스트 뉴스 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of '테스트 뉴스 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test entry rather than a real news item.\"}\n",
      "{'plausibility_score': '3', 'reason': \"The news '테스트 뉴스 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of '테스트 뉴스 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test headline rather than actual news content.\"}\n",
      "retrieved_news:[]\n",
      "Title: 뉴스 테스트\n",
      "Source: 나무위키, \n",
      "Content: 다양한 분야의 뉴스/시사 상식의 습득 수준을 객관적이고 체계적인 지표로 측정할 수 있도록 개발된 뉴스 상식 검정 시험이다. 2017년 3월 25일 시행된 1회 시험에서 최고 ...\n",
      "Title: TestingCatalog News on X: \"4. Test VEO 2 What will you ...\n",
      "Source: x.com, \n",
      "Content: Conversation. TestingCatalog News · @testingcatalog. 4. Test VEO 2 What will you make? Embedded video. 0:08. 9:40 PM · Feb 23, 2025. ·. 677. Views. 2. 7.\n",
      "Title: 테스트 방송 2\n",
      "Source: YouTube · 부평구의회, \n",
      "Content: ... من قصر الأسد يتحدث عن خططه من أجل مستقبل سوريا وارتباطه السابق بتنظيم القاعدة. BBC News عربي New 1.8M views · 24:04 · Go to channel · Using ...\n",
      "Title: Parents urged to check ratings after child car seats fail ...\n",
      "Source: wfmynews2.com, Feb 7, 2025\n",
      "Content: Consumer Reports exclusive child car seat testing recently revealed significant problems with two infant seats.\n",
      "Title: New online testing for learner's driver permit test gains ...\n",
      "Source: KHON2, 4 days ago\n",
      "Content: Students have one hour to answer 30 questions and the fee to take the online test is $12. Download the free KHON2 app for iOS or Android to stay ...\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of '테스트 뉴스 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on a date matching the given context (Feb 23, 2025), indicating that test-related news on this date is plausible.\\n3. However, the exact phrase '테스트 뉴스 2' does not appear in the retrieved news, and there's no specific context provided for this news item.\\n4. The retrieved news items are diverse and don't provide a clear pattern or context for '테스트 뉴스 2'.\\n5. Without more specific information about the content or source of '테스트 뉴스 2', it's difficult to assess its full plausibility.\\nGiven these factors, the news item could be real, but there's not enough evidence to confirm or deny its authenticity with high confidence.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of '테스트 뉴스 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on a date matching the given context (Feb 23, 2025), indicating that test-related news on this date is plausible.\\n3. However, the exact phrase '테스트 뉴스 2' does not appear in the retrieved news, and there's no specific context about what this test news might entail.\\n4. The retrieved news items are diverse and don't provide a clear pattern or context for what '테스트 뉴스 2' might be referring to.\\n5. Without more specific information about the content or source of '테스트 뉴스 2', it's difficult to ascertain its full plausibility.\\nGiven these factors, the news item could be real, but there's not enough corroborating evidence to rate it as highly plausible, nor is there any information to suggest it's false.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of '테스트 뉴스 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on the stated date (Feb 23, 2025), which aligns with the given news title format.\\n3. However, there's no direct mention of '테스트 뉴스 2' in the retrieved information, which prevents assigning a higher plausibility score.\\n4. The context of February 23, 2025, is consistent with some of the retrieved news items, adding some credibility.\\n5. The vague nature of the news title '테스트 뉴스 2' makes it difficult to completely rule out or confirm its plausibility without more specific content.\\nGiven these factors, the news item could be plausible, but there's not enough concrete evidence to rate it higher or lower on the plausibility scale.\"}\n",
      "retrieved_news:[]\n",
      "Title: 제3회 뉴스테스트 | 공모전\n",
      "Source: 여기부터, \n",
      "Content: 국제신문은 조선일보와 함께 전 국민의 뉴스 이해력 증진과 시사상식 능력을 높이기 위한 뉴스테스트(News Test) 3회 차 시험을 11월25일실시합니다. 뉴스테스트는 다양한 ...\n",
      "Title: 뉴스 테스트\n",
      "Source: 나무위키, \n",
      "Content: 다양한 분야의 뉴스/시사 상식의 습득 수준을 객관적이고 체계적인 지표로 측정할 수 있도록 개발된 뉴스 상식 검정 시험이다. 2017년 3월 25일 시행된 1회 시험에서 최고 ...\n",
      "Title: #27 women test #3 CMS before falling - Brandeis University\n",
      "Source: brandeisjudges.com, 1 day ago\n",
      "Content: – The 27th-ranked Brandeis University women's tennis team played several tightly-contested matches, but ultimately fell to third-ranked ...\n",
      "Title: #25 Fighting Illini Head West for Ranked Road Test at #3 ...\n",
      "Source: University of Illinois Athletics, 4 days ago\n",
      "Content: No. 25 Illinois takes on No. 3 UCLA away from home on Thursday at 8:30 p.m. CT.\n",
      "Title: Maine's new 3-day waiting period law could become test ...\n",
      "Source: Maine Public, 3 days ago\n",
      "Content: Maine's new, three-day waiting period on gun purchases passed the Legislature by the slimmest possible margin last year and narrowly averted ...\n",
      "{'plausibility_score': '5', 'reason': \"The news title '테스트 뉴스 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are some related items that suggest news tests or third iterations of events are plausible:\\n\\n1. The first retrieved news mentions a '제3회 뉴스테스트' (3rd News Test), which aligns with the concept of a third iteration.\\n2. Several retrieved items are about tests or third-ranked entities.\\n\\nHowever, without more specific details about the content of '테스트 뉴스 3', it's impossible to determine its full plausibility. The score of 5 reflects this uncertainty - it's neither clearly false nor fully plausible based on the limited information provided.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The news title '테스트 뉴스 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are some related items that suggest news tests or third iterations of events are plausible:\\n\\n1. The first retrieved news mentions a '제3회 뉴스테스트' (3rd News Test), which aligns with the concept of a third iteration.\\n2. Several retrieved items are about tests or third-ranked entities.\\n\\nHowever, without more specific details about the content of '테스트 뉴스 3', it's impossible to determine its full plausibility. The score of 5 reflects this uncertainty - it's neither clearly false nor fully plausible based on the limited information provided.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The news title '테스트 뉴스 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are several references to news tests and the number 3 in the provided information. The first two retrieved items mention 'News Test' and specifically a '3rd News Test'. However, these seem to be about news literacy tests rather than actual news articles. The other retrieved items are unrelated sports news. Given the vague nature of the title and the partial matches in the retrieved information, I've assigned a neutral plausibility score of 5. The news could be plausible, but there's not enough specific information to confirm or deny its validity with confidence.\"}\n",
      "AUC-ROC Score: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# 🔹 테스트 데이터 로드 (가상의 뉴스 데이터)\n",
    "test_news = [\"테스트 뉴스 1\", \"테스트 뉴스 2\", \"테스트 뉴스 3\"]\n",
    "true_labels = [1, 0, 1]  # 1: Real, 0: Fake\n",
    "\n",
    "# 🔹 개연성 점수 예측\n",
    "predicted_scores = [generate_final_score(news, retrieve_relevant_news(news)) for news in test_news]\n",
    "\n",
    "# 🔹 AUC-ROC 계산\n",
    "auc_score = roc_auc_score(true_labels, predicted_scores)\n",
    "print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_news:[]\n",
      "Title: Presidential Election Results Map: Trump Wins\n",
      "Source: The New York Times, Nov 5, 2024\n",
      "Content: Donald J. Trump has won the presidency, improving upon his 2020 performance in both red and blue states and capturing enough swing states to reach 270 ...\n",
      "Title: Wins Come All Day Under President Donald J. Trump\n",
      "Source: The White House (.gov), Feb 14, 2025\n",
      "Content: It was another week filled with endless wins for the American people under President Donald J. Trump. Here are only a few of the many ...\n",
      "Title: Just how big was Donald Trump's election victory?\n",
      "Source: BBC, Nov 22, 2024\n",
      "Content: Trump's win over Harris in 2024 appears more comfortable. He won 312 votes in the US electoral college compared with Harris's 226.\n",
      "Title: Donald Trump wins the 2024 presidential election\n",
      "Source: NPR, Nov 6, 2024\n",
      "Content: Becoming just the second president to be defeated and then reelected to a subsequent term, former President Donald Trump defeated Vice ...\n",
      "Title: The size of Donald Trump's 2024 election victory ...\n",
      "Source: PBS, Nov 24, 2024\n",
      "Content: Trump won both the Electoral College and the popular vote; in fact, Trump this year became only the second Republican to win the popular vote since 1988.\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details about the election results, including electoral college votes and popular vote outcomes. The White House (.gov) website also mentions Trump's presidency in February 2025, which aligns with the current date given (February 23, 2025). The consistency across various sources and the specificity of the information strongly support the plausibility of Trump's win. However, a score of 9 rather than 10 is given to account for the small possibility of very recent, unreported developments or the potential for misinformation, even though this seems unlikely given the range and credibility of the sources provided.\"}\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details such as electoral college votes (312 for Trump vs 226 for Harris) and mention that Trump won both the electoral college and the popular vote. The White House .gov site also references Trump as the current president in February 2025. While there's always a small possibility of misinformation or unforeseen events, the consistency and specificity across multiple credible sources strongly support the plausibility of Trump's win. The score is 9 instead of 10 only because the news is from the past (2024) relative to the given current date (February 2025), and there's a slight possibility of very recent, unreported developments.\"}\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details about the election results, including electoral college votes and popular vote outcomes. The White House (.gov) website also mentions Trump's presidency in February 2025, which aligns with the current date given (February 23, 2025). The consistency across various sources and the specificity of the information strongly support the plausibility of Trump's win. However, a score of 9 rather than 10 is given to account for the small possibility of very recent, unreported developments or the potential for misinformation, even though this seems unlikely given the range and credibility of the sources provided.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_final_score(\"Trump wins\",retrieve_relevant_news(\"Trump wins\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Appeals court ruling will let some Kansas vote...</td>\n",
       "      <td>(Reuters) - Thousands of Kansas residents who ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 11, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Speaker Ryan urges conservative unity in...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. House Speaker Paul...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 3, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once credited with Trump's success, Bannon qui...</td>\n",
       "      <td>WASHINGTON (Reuters) - When President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>August 18, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump To Gut Coast Guard, Airport Security, A...</td>\n",
       "      <td>Donald Trump s obsession with building a massi...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 8, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump says Senate Republicans likely to pass h...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 28, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Appeals court ruling will let some Kansas vote...   \n",
       "1  House Speaker Ryan urges conservative unity in...   \n",
       "2  Once credited with Trump's success, Bannon qui...   \n",
       "3   Trump To Gut Coast Guard, Airport Security, A...   \n",
       "4  Trump says Senate Republicans likely to pass h...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  (Reuters) - Thousands of Kansas residents who ...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - U.S. House Speaker Paul...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - When President Donald T...  politicsNews   \n",
       "3  Donald Trump s obsession with building a massi...          News   \n",
       "4  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "\n",
       "                date  label  \n",
       "0     June 11, 2016       1  \n",
       "1  February 3, 2016       1  \n",
       "2   August 18, 2017       1  \n",
       "3      March 8, 2017      0  \n",
       "4     June 28, 2017       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load Dataset\n",
    "true_data = pd.read_csv('/Users/yoonjincho/Desktop/FakeNews_kaggle/True.csv')\n",
    "fake_data = pd.read_csv('/Users/yoonjincho/Desktop/FakeNews_kaggle/Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "data = pd.concat([true_data, fake_data], ignore_index = True).sample(frac=1).reset_index().drop(columns = ['index'])\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

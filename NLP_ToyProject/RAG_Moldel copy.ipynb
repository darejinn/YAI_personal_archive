{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° API key ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from openai import OpenAI\n",
    "from serpapi import GoogleSearch \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "from langchain_anthropic import ChatAnthropic, AnthropicLLM\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
    "from langchain.memory import SimpleMemory\n",
    "from datetime import datetime\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import json\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrap_openai(openai.Client())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ë° SerpAPI í‚¤ ì„¤ì •\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERP_API_KEY = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ\n",
    "FAISS_INDEX_PATH = Path('local/news-please/faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DPR ê¸°ë°˜ ì‚¬ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPR():\n",
    "    def __init__(self):\n",
    "        \"\"\"ì‚¬ë‚´ ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ í™œìš©í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” DPR í´ë˜ìŠ¤\"\"\"\n",
    "        self.ds = datasets.load_dataset('sanxing/advfake_news_please')['train']\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.index_dpr()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def index_dpr(self):\n",
    "        \"\"\"DPR ê¸°ë°˜ ë‰´ìŠ¤ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•\"\"\"\n",
    "        from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "        faiss_path = FAISS_INDEX_PATH / 'my_index.faiss'\n",
    "        if faiss_path.exists():\n",
    "            print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...')\n",
    "            self.ds.load_faiss_index('embeddings', str(faiss_path))\n",
    "            return\n",
    "\n",
    "        print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...')\n",
    "        ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(self.device)\n",
    "        ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "        # ğŸ”¹ ë‰´ìŠ¤ ì œëª©ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n",
    "        ds_with_embeddings = self.ds.map(lambda example: {\n",
    "            'embeddings': ctx_encoder(**ctx_tokenizer(example[\"title\"], return_tensors=\"pt\", padding=True).to(self.device))[0].cpu().numpy()\n",
    "        }, batched=True, batch_size=64)\n",
    "\n",
    "        ds_with_embeddings.add_faiss_index(column='embeddings')\n",
    "\n",
    "        print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì¤‘...')\n",
    "        ds_with_embeddings.save_faiss_index('embeddings', str(faiss_path))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, query):\n",
    "        \"\"\"ì…ë ¥ëœ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ 10ê°œ ê²€ìƒ‰\"\"\"\n",
    "        from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "\n",
    "        q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(self.device)\n",
    "        q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "        # ğŸ”¹ ì…ë ¥ ì¿¼ë¦¬ë¥¼ DPR ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "        question_embedding = q_encoder(**q_tokenizer(query, return_tensors=\"pt\").to(self.device))[0][0].cpu().numpy()\n",
    "        \n",
    "        # ğŸ”¹ FAISS ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        scores, retrieved_examples = self.ds.get_nearest_examples('embeddings', question_embedding, k=5)\n",
    "\n",
    "        # ğŸ”¹ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜\n",
    "        retrieved_examples = [dict(zip(retrieved_examples, t)) for t in zip(*retrieved_examples.values())]\n",
    "\n",
    "        return scores, retrieved_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer,\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    ")\n",
    "\n",
    "FAISS_INDEX_PATH = Path(\"faiss_index\")  # ì €ì¥í•  í´ë”\n",
    "DATASET_SAVE_PATH = Path(\"news_dataset\")  # ë°ì´í„°ì…‹ ì €ì¥ ìœ„ì¹˜\n",
    "FAISS_FILE = FAISS_INDEX_PATH / \"my_index.faiss\"\n",
    "\n",
    "class DPR():\n",
    "    def __init__(self):\n",
    "        \"\"\"ì‚¬ë‚´ ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ í™œìš©í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” DPR í´ë˜ìŠ¤\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # ğŸ”¹ ì €ì¥ëœ ë°ì´í„°ì…‹ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "        if DATASET_SAVE_PATH.exists():\n",
    "            print(\"ğŸ”¹ ì €ì¥ëœ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\")\n",
    "            self.ds = datasets.load_from_disk(str(DATASET_SAVE_PATH))\n",
    "        else:\n",
    "            print(\"ğŸ”¹ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "            self.ds = datasets.load_dataset('sanxing/advfake_news_please')['train']\n",
    "            self.ds.save_to_disk(str(DATASET_SAVE_PATH))  # ì €ì¥\n",
    "\n",
    "        # FAISS ì¸ë±ì‹±\n",
    "        self.index_dpr()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def index_dpr(self):\n",
    "        \"\"\"DPR ê¸°ë°˜ ë‰´ìŠ¤ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•\"\"\"\n",
    "        if FAISS_FILE.exists():\n",
    "            print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...')\n",
    "            self.ds.load_faiss_index('embeddings', str(FAISS_FILE))\n",
    "            return\n",
    "\n",
    "        print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...')\n",
    "        ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(self.device)\n",
    "        ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "        def embed_batch(examples):\n",
    "            inputs = ctx_tokenizer(examples[\"title\"], return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "            embeddings = ctx_encoder(**inputs).pooler_output.cpu().numpy()\n",
    "            return {\"embeddings\": embeddings}\n",
    "\n",
    "        ds_with_embeddings = self.ds.map(embed_batch, batched=True, batch_size=64)\n",
    "        ds_with_embeddings.add_faiss_index(column='embeddings')\n",
    "\n",
    "        print('ğŸ”¹ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì¤‘...')\n",
    "        FAISS_INDEX_PATH.mkdir(parents=True, exist_ok=True)\n",
    "        ds_with_embeddings.save_faiss_index('embeddings', str(FAISS_FILE))\n",
    "\n",
    "        # ğŸ”¹ ë°ì´í„°ì…‹ë„ í•¨ê»˜ ì €ì¥\n",
    "        ds_with_embeddings.save_to_disk(str(DATASET_SAVE_PATH))\n",
    "        self.ds = ds_with_embeddings  # ë©”ëª¨ë¦¬ì— ì €ì¥\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, query):\n",
    "        \"\"\"ì…ë ¥ëœ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ 5ê°œ ê²€ìƒ‰\"\"\"\n",
    "        q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(self.device)\n",
    "        q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "        # ğŸ”¹ ì…ë ¥ ì¿¼ë¦¬ë¥¼ DPR ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "        inputs = q_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "        question_embedding = q_encoder(**inputs).pooler_output.cpu().numpy()[0]\n",
    "\n",
    "        # ğŸ”¹ FAISS ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        scores, retrieved_examples = self.ds.get_nearest_examples('embeddings', question_embedding, k=5)\n",
    "\n",
    "        # ğŸ”¹ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜\n",
    "        retrieved_examples = [dict(zip(retrieved_examples, t)) for t in zip(*retrieved_examples.values())]\n",
    "\n",
    "        return scores, retrieved_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (1.10.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp_1/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch datasets faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Google SerpAPI ê¸°ë°˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_serpapi(q):\n",
    "    \"\"\"Google SerpAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê²€ìƒ‰\"\"\"\n",
    "    params = {\n",
    "        \"api_key\": SERP_API_KEY,  # SerpAPI í‚¤\n",
    "        \"engine\": \"google\",  # Google ê²€ìƒ‰ ì—”ì§„ ì‚¬ìš©\n",
    "        \"q\": q,  # ê²€ìƒ‰ì–´\n",
    "        \"location\": \"Austin, Texas, United States\",  # ê²€ìƒ‰ ì§€ì—­ ì§€ì •\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"gl\": \"us\",  # êµ­ê°€ ì„¤ì • (ë¯¸êµ­)\n",
    "        \"hl\": \"en\",  # ì–¸ì–´ ì„¤ì • (ì˜ì–´)\n",
    "        \"num\": \"30\"  # ê²€ìƒ‰ ê²°ê³¼ ìµœëŒ€ 30ê°œ ê°€ì ¸ì˜¤ê¸°\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)  # SerpAPIë¥¼ ì‚¬ìš©í•œ Google ê²€ìƒ‰ ê°ì²´ ìƒì„±\n",
    "    results = search.get_dict()  # JSON í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    return results  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "def concat_snippets(organic_results):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ê¸°ì‚¬ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ í•„í„°ë§í•˜ê³  ìš”ì•½\"\"\"\n",
    "    organic_results = [result for result in organic_results if 'snippet' in result]  # snippetì´ ìˆëŠ” ê¸°ì‚¬ë§Œ í•„í„°ë§\n",
    "    organic_results = [result for result in organic_results if 'NBC' not in result['source'] and 'NBC' not in result['title']]  # NBC ë‰´ìŠ¤ ì œì™¸\n",
    "    organic_results = [result for result in organic_results if 'fact' not in result['link']]  # 'fact'ê°€ í¬í•¨ëœ ë§í¬ ì œì™¸ (íŒ©íŠ¸ì²´í¬ ê¸°ì‚¬ í•„í„°ë§)\n",
    "    organic_results = organic_results[:5]  # ìƒìœ„ 5ê°œ ê¸°ì‚¬ë§Œ ì„ íƒ\n",
    "\n",
    "    return '\\n'.join([\n",
    "        f'Title: {result[\"title\"]}\\nSource: {result[\"source\"]}, {result[\"date\"] if \"date\" in result else \"\"}\\nContent: {result[\"snippet\"]}' \n",
    "        for result in organic_results\n",
    "    ])\n",
    "\n",
    "def get_google_ctx(q):\n",
    "    \"\"\"ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì…ë ¥ì— ì‚¬ìš©í•  í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "    search_results = search_serpapi(q)  # Google ê²€ìƒ‰ ì‹¤í–‰\n",
    "    if 'organic_results' in search_results:\n",
    "        return concat_snippets(search_results['organic_results'])  # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ í›„ ë°˜í™˜\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_news(news_headline):\n",
    "    \"\"\"ì‚¬ë‚´ ë‰´ìŠ¤ ë° Google ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰\"\"\"\n",
    "    #dpr = DPR()\n",
    "    #_, retrieved_news = dpr.search(news_headline)\n",
    "    retrieved_news=[]\n",
    "    print(f\"retrieved_news:{retrieved_news}\")\n",
    "    google_results = get_google_ctx(news_headline)\n",
    "    print(google_results)\n",
    "    \n",
    "    return retrieved_news + [google_results]\n",
    "\n",
    "def get_plausibility_score(news_text, retrieved_news):\n",
    "    \"\"\"GPT-4oë¥¼ ì´ìš©í•˜ì—¬ ë‰´ìŠ¤ì˜ ê°œì—°ì„± ì ìˆ˜ ì˜ˆì¸¡\"\"\"\n",
    "    input_data = {\"news_text\":news_text, \"retrieved_news\" : retrieved_news}\n",
    "    result = chain_1.invoke(input_data)\n",
    "    print(result)\n",
    "    return result['plausibility_score']\n",
    "\n",
    "\n",
    "def generate_final_score(news_text, retrieved_news):\n",
    "    \"\"\"ìƒ˜í”Œë§ì„ í†µí•´ ìµœì¢… ê°œì—°ì„± ì ìˆ˜ ìƒì„± (0~1 ë²”ìœ„)\"\"\"\n",
    "    scores = [get_plausibility_score(news_text, retrieved_news)['plausibility_score'] for _ in range(3)]\n",
    "    scores = list(map(int, scores))\n",
    "    final_score = sum(scores) / len(scores)\n",
    "    return final_score / 10  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜í•™ê³¼í•™ê°œìš” ê²€í†  LLM\n",
    "llm1 = ChatOpenAI(temperature=1,               # ì°½ì˜ì„± (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # ìµœëŒ€ í† í°ìˆ˜\n",
    "                 model_name='gpt-4o',  # ëª¨ë¸ëª…\n",
    "                )\n",
    "\n",
    "llm2 = ChatAnthropic(model='claude-3-5-sonnet-20240620',max_tokens=8192)\n",
    "\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­ì„ íŒŒì‹±\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"plausibility_score\",\n",
    "        description=\"A numerical score between 1 and 10 that represents how plausible the given statement is. \"\n",
    "                    \"1 means 'completely false', while 10 means 'fully plausible'.\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"reason\",\n",
    "        description=\"A textual explanation providing the reasoning behind the assigned plausibility score.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt_template_1 = \"\"\"\n",
    "\n",
    "    Today is March 26, 2024. You predict the plausibility of a news you havenâ€™t seen.\n",
    "\n",
    "    News: \"{news_text}\"\n",
    "\n",
    "    Retrieved News:\n",
    "    {retrieved_news}\n",
    "\n",
    "    Based on the provided information, rate the plausibility of the news on a scale of 1 to 10 (1: completely false, 10: fully plausible). Also, give the proper reason.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=prompt_template_1,\n",
    "    input_variables=[\"news_text\",\"retrieved news\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | llm2 | output_parser  # í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_news:[]\n",
      "Title: ë‰´ìŠ¤1\n",
      "Source: ë‰´ìŠ¤1, \n",
      "Content: ìœ¤ì„ì—´ íƒ„í•µì‹¬íŒÂ·ì´ì¬ëª… ì„ ê±°ë²• 2ì‹¬ ë³€ë¡ ì¢…ê²°â€¦ Â· \"ìë°±í•˜ê³  ì‚¬ê³¼\" vs \"ì •ë‹¹ì„± ë¶€ê°\"â€¦'å°¹ ìµœí›„ì§„ìˆ ' ë†“ê³ ë„ ì‹œë¯¼ì‚¬íšŒ 'ì©' Â· [íƒ„í•µì‹¬íŒì˜ ì–¼êµ´ë“¤]â‘£êµ­ë¬´ì´ë¦¬ í•œë•ìˆ˜â€¦\n",
      "Title: CONNECT ì„œë¹„ìŠ¤\n",
      "Source: ë‰´ìŠ¤1, \n",
      "Content: ë‰´ìŠ¤1, AFP ë° Reuter ë‰´ìŠ¤ì •ë³´ ë° ì‚¬ì§„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—´ëŒí•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¡œ, 24ì‹œê°„ êµ­ë‚´ì™¸ ì†ë³´ë¥¼ í•œ ëˆˆì— ì ‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§¤ì²´ì‚¬,ê¸°ì—…, ê´€ê³µì„œ, ê°œì¸ ë“± ì´ìš© ...\n",
      "Title: ë‰´ìŠ¤1 (@News1Kr) / X\n",
      "Source: x.com, \n",
      "Content: ì‚¬ì‹¤ ì•ì— ê²¸ì†í•œ ë¯¼ì˜ í†µì‹  ë‰´ìŠ¤1ì…ë‹ˆë‹¤. ìœ íŠœë¸Œ : http://youtube.com/user/news1korea. Translate bio.\n",
      "Title: ë‰´ìŠ¤ í…ŒìŠ¤íŠ¸\n",
      "Source: ë‚˜ë¬´ìœ„í‚¤, \n",
      "Content: ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë‰´ìŠ¤/ì‹œì‚¬ ìƒì‹ì˜ ìŠµë“ ìˆ˜ì¤€ì„ ê°ê´€ì ì´ê³  ì²´ê³„ì ì¸ ì§€í‘œë¡œ ì¸¡ì •í•  ìˆ˜ ìˆë„ë¡ ê°œë°œëœ ë‰´ìŠ¤ ìƒì‹ ê²€ì • ì‹œí—˜ì´ë‹¤. 2017ë…„ 3ì›” 25ì¼ ì‹œí–‰ëœ 1íšŒ ì‹œí—˜ì—ì„œ ìµœê³  ...\n",
      "Title: Minuteman III test launch showcases readiness of US ...\n",
      "Source: Space Force (.mil), 4 days ago\n",
      "Content: Minuteman III test launch showcases readiness of US nuclear force's safe, effective deterrent. Published Feb. 19, 2025; By Staff Sgt. Joshua ...\n",
      "{'plausibility_score': '3', 'reason': \"The news 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test entry rather than a real news item.\"}\n",
      "{'plausibility_score': '3', 'reason': \"The news 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test entry rather than a real news item.\"}\n",
      "{'plausibility_score': '3', 'reason': \"The news 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1' (Test News 1) is very vague and lacks any specific content, making it difficult to assess its plausibility. None of the retrieved news articles directly correspond to or mention this specific news item. The retrieved information mostly relates to other news sources or general news services. Without any context or details about the content of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1', it's not possible to verify its accuracy or relevance. The low plausibility score is assigned due to the lack of supporting evidence and the generic nature of the news title, which could potentially be a placeholder or test headline rather than actual news content.\"}\n",
      "retrieved_news:[]\n",
      "Title: ë‰´ìŠ¤ í…ŒìŠ¤íŠ¸\n",
      "Source: ë‚˜ë¬´ìœ„í‚¤, \n",
      "Content: ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë‰´ìŠ¤/ì‹œì‚¬ ìƒì‹ì˜ ìŠµë“ ìˆ˜ì¤€ì„ ê°ê´€ì ì´ê³  ì²´ê³„ì ì¸ ì§€í‘œë¡œ ì¸¡ì •í•  ìˆ˜ ìˆë„ë¡ ê°œë°œëœ ë‰´ìŠ¤ ìƒì‹ ê²€ì • ì‹œí—˜ì´ë‹¤. 2017ë…„ 3ì›” 25ì¼ ì‹œí–‰ëœ 1íšŒ ì‹œí—˜ì—ì„œ ìµœê³  ...\n",
      "Title: TestingCatalog News on X: \"4. Test VEO 2 What will you ...\n",
      "Source: x.com, \n",
      "Content: Conversation. TestingCatalog News Â· @testingcatalog. 4. Test VEO 2 What will you make? Embedded video. 0:08. 9:40 PM Â· Feb 23, 2025. Â·. 677. Views. 2. 7.\n",
      "Title: í…ŒìŠ¤íŠ¸ ë°©ì†¡ 2\n",
      "Source: YouTube Â· ë¶€í‰êµ¬ì˜íšŒ, \n",
      "Content: ... Ù…Ù† Ù‚ØµØ± Ø§Ù„Ø£Ø³Ø¯ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ø®Ø·Ø·Ù‡ Ù…Ù† Ø£Ø¬Ù„ Ù…Ø³ØªÙ‚Ø¨Ù„ Ø³ÙˆØ±ÙŠØ§ ÙˆØ§Ø±ØªØ¨Ø§Ø·Ù‡ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø¨ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©. BBC News Ø¹Ø±Ø¨ÙŠ New 1.8M views Â· 24:04 Â· Go to channel Â· Using ...\n",
      "Title: Parents urged to check ratings after child car seats fail ...\n",
      "Source: wfmynews2.com, Feb 7, 2025\n",
      "Content: Consumer Reports exclusive child car seat testing recently revealed significant problems with two infant seats.\n",
      "Title: New online testing for learner's driver permit test gains ...\n",
      "Source: KHON2, 4 days ago\n",
      "Content: Students have one hour to answer 30 questions and the fee to take the online test is $12. Download the free KHON2 app for iOS or Android to stay ...\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on a date matching the given context (Feb 23, 2025), indicating that test-related news on this date is plausible.\\n3. However, the exact phrase 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' does not appear in the retrieved news, and there's no specific context provided for this news item.\\n4. The retrieved news items are diverse and don't provide a clear pattern or context for 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2'.\\n5. Without more specific information about the content or source of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2', it's difficult to assess its full plausibility.\\nGiven these factors, the news item could be real, but there's not enough evidence to confirm or deny its authenticity with high confidence.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on a date matching the given context (Feb 23, 2025), indicating that test-related news on this date is plausible.\\n3. However, the exact phrase 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' does not appear in the retrieved news, and there's no specific context about what this test news might entail.\\n4. The retrieved news items are diverse and don't provide a clear pattern or context for what 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' might be referring to.\\n5. Without more specific information about the content or source of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2', it's difficult to ascertain its full plausibility.\\nGiven these factors, the news item could be real, but there's not enough corroborating evidence to rate it as highly plausible, nor is there any information to suggest it's false.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The plausibility of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' (Test News 2) is rated as moderate (5/10) for the following reasons:\\n1. The retrieved news items include several test-related entries, suggesting that test news or content is not uncommon.\\n2. One of the retrieved items specifically mentions 'Test VEO 2' on the stated date (Feb 23, 2025), which aligns with the given news title format.\\n3. However, there's no direct mention of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' in the retrieved information, which prevents assigning a higher plausibility score.\\n4. The context of February 23, 2025, is consistent with some of the retrieved news items, adding some credibility.\\n5. The vague nature of the news title 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2' makes it difficult to completely rule out or confirm its plausibility without more specific content.\\nGiven these factors, the news item could be plausible, but there's not enough concrete evidence to rate it higher or lower on the plausibility scale.\"}\n",
      "retrieved_news:[]\n",
      "Title: ì œ3íšŒ ë‰´ìŠ¤í…ŒìŠ¤íŠ¸ | ê³µëª¨ì „\n",
      "Source: ì—¬ê¸°ë¶€í„°, \n",
      "Content: êµ­ì œì‹ ë¬¸ì€ ì¡°ì„ ì¼ë³´ì™€ í•¨ê»˜ ì „ êµ­ë¯¼ì˜ ë‰´ìŠ¤ ì´í•´ë ¥ ì¦ì§„ê³¼ ì‹œì‚¬ìƒì‹ ëŠ¥ë ¥ì„ ë†’ì´ê¸° ìœ„í•œ ë‰´ìŠ¤í…ŒìŠ¤íŠ¸(News Test) 3íšŒ ì°¨ ì‹œí—˜ì„ 11ì›”25ì¼ì‹¤ì‹œí•©ë‹ˆë‹¤. ë‰´ìŠ¤í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ì–‘í•œ ...\n",
      "Title: ë‰´ìŠ¤ í…ŒìŠ¤íŠ¸\n",
      "Source: ë‚˜ë¬´ìœ„í‚¤, \n",
      "Content: ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë‰´ìŠ¤/ì‹œì‚¬ ìƒì‹ì˜ ìŠµë“ ìˆ˜ì¤€ì„ ê°ê´€ì ì´ê³  ì²´ê³„ì ì¸ ì§€í‘œë¡œ ì¸¡ì •í•  ìˆ˜ ìˆë„ë¡ ê°œë°œëœ ë‰´ìŠ¤ ìƒì‹ ê²€ì • ì‹œí—˜ì´ë‹¤. 2017ë…„ 3ì›” 25ì¼ ì‹œí–‰ëœ 1íšŒ ì‹œí—˜ì—ì„œ ìµœê³  ...\n",
      "Title: #27 women test #3 CMS before falling - Brandeis University\n",
      "Source: brandeisjudges.com, 1 day ago\n",
      "Content: â€“ The 27th-ranked Brandeis University women's tennis team played several tightly-contested matches, but ultimately fell to third-ranked ...\n",
      "Title: #25 Fighting Illini Head West for Ranked Road Test at #3 ...\n",
      "Source: University of Illinois Athletics, 4 days ago\n",
      "Content: No. 25 Illinois takes on No. 3 UCLA away from home on Thursday at 8:30 p.m. CT.\n",
      "Title: Maine's new 3-day waiting period law could become test ...\n",
      "Source: Maine Public, 3 days ago\n",
      "Content: Maine's new, three-day waiting period on gun purchases passed the Legislature by the slimmest possible margin last year and narrowly averted ...\n",
      "{'plausibility_score': '5', 'reason': \"The news title 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are some related items that suggest news tests or third iterations of events are plausible:\\n\\n1. The first retrieved news mentions a 'ì œ3íšŒ ë‰´ìŠ¤í…ŒìŠ¤íŠ¸' (3rd News Test), which aligns with the concept of a third iteration.\\n2. Several retrieved items are about tests or third-ranked entities.\\n\\nHowever, without more specific details about the content of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3', it's impossible to determine its full plausibility. The score of 5 reflects this uncertainty - it's neither clearly false nor fully plausible based on the limited information provided.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The news title 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are some related items that suggest news tests or third iterations of events are plausible:\\n\\n1. The first retrieved news mentions a 'ì œ3íšŒ ë‰´ìŠ¤í…ŒìŠ¤íŠ¸' (3rd News Test), which aligns with the concept of a third iteration.\\n2. Several retrieved items are about tests or third-ranked entities.\\n\\nHowever, without more specific details about the content of 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3', it's impossible to determine its full plausibility. The score of 5 reflects this uncertainty - it's neither clearly false nor fully plausible based on the limited information provided.\"}\n",
      "{'plausibility_score': '5', 'reason': \"The news title 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3' (Test News 3) is very generic and doesn't provide much context. While there's no direct match in the retrieved news, there are several references to news tests and the number 3 in the provided information. The first two retrieved items mention 'News Test' and specifically a '3rd News Test'. However, these seem to be about news literacy tests rather than actual news articles. The other retrieved items are unrelated sports news. Given the vague nature of the title and the partial matches in the retrieved information, I've assigned a neutral plausibility score of 5. The news could be plausible, but there's not enough specific information to confirm or deny its validity with confidence.\"}\n",
      "AUC-ROC Score: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (ê°€ìƒì˜ ë‰´ìŠ¤ ë°ì´í„°)\n",
    "test_news = [\"í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 1\", \"í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 2\", \"í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ 3\"]\n",
    "true_labels = [1, 0, 1]  # 1: Real, 0: Fake\n",
    "\n",
    "# ğŸ”¹ ê°œì—°ì„± ì ìˆ˜ ì˜ˆì¸¡\n",
    "predicted_scores = [generate_final_score(news, retrieve_relevant_news(news)) for news in test_news]\n",
    "\n",
    "# ğŸ”¹ AUC-ROC ê³„ì‚°\n",
    "auc_score = roc_auc_score(true_labels, predicted_scores)\n",
    "print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_news:[]\n",
      "Title: Presidential Election Results Map: Trump Wins\n",
      "Source: The New York Times, Nov 5, 2024\n",
      "Content: Donald J. Trump has won the presidency, improving upon his 2020 performance in both red and blue states and capturing enough swing states to reach 270 ...\n",
      "Title: Wins Come All Day Under President Donald J. Trump\n",
      "Source: The White House (.gov), Feb 14, 2025\n",
      "Content: It was another week filled with endless wins for the American people under President Donald J. Trump. Here are only a few of the many ...\n",
      "Title: Just how big was Donald Trump's election victory?\n",
      "Source: BBC, Nov 22, 2024\n",
      "Content: Trump's win over Harris in 2024 appears more comfortable. He won 312 votes in the US electoral college compared with Harris's 226.\n",
      "Title: Donald Trump wins the 2024 presidential election\n",
      "Source: NPR, Nov 6, 2024\n",
      "Content: Becoming just the second president to be defeated and then reelected to a subsequent term, former President Donald Trump defeated Vice ...\n",
      "Title: The size of Donald Trump's 2024 election victory ...\n",
      "Source: PBS, Nov 24, 2024\n",
      "Content: Trump won both the Electoral College and the popular vote; in fact, Trump this year became only the second Republican to win the popular vote since 1988.\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details about the election results, including electoral college votes and popular vote outcomes. The White House (.gov) website also mentions Trump's presidency in February 2025, which aligns with the current date given (February 23, 2025). The consistency across various sources and the specificity of the information strongly support the plausibility of Trump's win. However, a score of 9 rather than 10 is given to account for the small possibility of very recent, unreported developments or the potential for misinformation, even though this seems unlikely given the range and credibility of the sources provided.\"}\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details such as electoral college votes (312 for Trump vs 226 for Harris) and mention that Trump won both the electoral college and the popular vote. The White House .gov site also references Trump as the current president in February 2025. While there's always a small possibility of misinformation or unforeseen events, the consistency and specificity across multiple credible sources strongly support the plausibility of Trump's win. The score is 9 instead of 10 only because the news is from the past (2024) relative to the given current date (February 2025), and there's a slight possibility of very recent, unreported developments.\"}\n",
      "{'plausibility_score': '9', 'reason': \"The news 'Trump wins' appears highly plausible based on the retrieved information. Multiple reputable sources (The New York Times, BBC, NPR, PBS) report Trump's victory in the 2024 presidential election. These sources provide specific details about the election results, including electoral college votes and popular vote outcomes. The White House (.gov) website also mentions Trump's presidency in February 2025, which aligns with the current date given (February 23, 2025). The consistency across various sources and the specificity of the information strongly support the plausibility of Trump's win. However, a score of 9 rather than 10 is given to account for the small possibility of very recent, unreported developments or the potential for misinformation, even though this seems unlikely given the range and credibility of the sources provided.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_final_score(\"Trump wins\",retrieve_relevant_news(\"Trump wins\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Appeals court ruling will let some Kansas vote...</td>\n",
       "      <td>(Reuters) - Thousands of Kansas residents who ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 11, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Speaker Ryan urges conservative unity in...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. House Speaker Paul...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 3, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once credited with Trump's success, Bannon qui...</td>\n",
       "      <td>WASHINGTON (Reuters) - When President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>August 18, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump To Gut Coast Guard, Airport Security, A...</td>\n",
       "      <td>Donald Trump s obsession with building a massi...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 8, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump says Senate Republicans likely to pass h...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 28, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Appeals court ruling will let some Kansas vote...   \n",
       "1  House Speaker Ryan urges conservative unity in...   \n",
       "2  Once credited with Trump's success, Bannon qui...   \n",
       "3   Trump To Gut Coast Guard, Airport Security, A...   \n",
       "4  Trump says Senate Republicans likely to pass h...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  (Reuters) - Thousands of Kansas residents who ...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - U.S. House Speaker Paul...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - When President Donald T...  politicsNews   \n",
       "3  Donald Trump s obsession with building a massi...          News   \n",
       "4  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "\n",
       "                date  label  \n",
       "0     June 11, 2016       1  \n",
       "1  February 3, 2016       1  \n",
       "2   August 18, 2017       1  \n",
       "3      March 8, 2017      0  \n",
       "4     June 28, 2017       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load Dataset\n",
    "true_data = pd.read_csv('/Users/yoonjincho/Desktop/FakeNews_kaggle/True.csv')\n",
    "fake_data = pd.read_csv('/Users/yoonjincho/Desktop/FakeNews_kaggle/Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "data = pd.concat([true_data, fake_data], ignore_index = True).sample(frac=1).reset_index().drop(columns = ['index'])\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:40.107329Z",
     "iopub.status.busy": "2025-02-20T19:42:40.106982Z",
     "iopub.status.idle": "2025-02-20T19:42:47.758407Z",
     "shell.execute_reply": "2025-02-20T19:42:47.757529Z",
     "shell.execute_reply.started": "2025-02-20T19:42:40.107301Z"
    },
    "executionInfo": {
     "elapsed": 13125,
     "status": "ok",
     "timestamp": 1740061781607,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "hgg3bz16IHUR",
    "outputId": "db8bb3cc-6e23-4f23-8e3e-73207e000238",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pycaret in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.34.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret) (8.1.5)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.67.1)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.4)\n",
      "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.4)\n",
      "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.11.4)\n",
      "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.4.2)\n",
      "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.3)\n",
      "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.12.4)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.7.0)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.5.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.60.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.5)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (8.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.10.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.0)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.5.0)\n",
      "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.7.5)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.3.7)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5)\n",
      "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.24.1)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.2.1)\n",
      "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.15)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.10.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.14.4)\n",
      "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.26.0)\n",
      "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.1.3)\n",
      "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.4)\n",
      "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (24.2)\n",
      "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.21.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (75.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (3.0.48)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (2.19.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (2.9.0.post0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<1.27,>=1.21->pycaret) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2025.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret) (9.0.0)\n",
      "Requirement already satisfied: dash>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.18.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.12)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.4.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.11)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (2025.1.31)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.6)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.12.2)\n",
      "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.3.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<3.8.0->pycaret) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27,>=1.21->pycaret) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27,>=1.21->pycaret) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<1.27,>=1.21->pycaret) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<1.27,>=1.21->pycaret) (2024.2.0)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<1.27,>=1.21->pycaret) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install specific libraries\n",
    "! pip install transformers\n",
    "! pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:47.760276Z",
     "iopub.status.busy": "2025-02-20T19:42:47.759969Z",
     "iopub.status.idle": "2025-02-20T19:42:47.766134Z",
     "shell.execute_reply": "2025-02-20T19:42:47.765227Z",
     "shell.execute_reply.started": "2025-02-20T19:42:47.760250Z"
    },
    "id": "s6IIW6gGIVUJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:47.767845Z",
     "iopub.status.busy": "2025-02-20T19:42:47.767641Z",
     "iopub.status.idle": "2025-02-20T19:42:49.109282Z",
     "shell.execute_reply": "2025-02-20T19:42:49.108396Z",
     "shell.execute_reply.started": "2025-02-20T19:42:47.767827Z"
    },
    "executionInfo": {
     "elapsed": 9071,
     "status": "ok",
     "timestamp": 1740061820909,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "63QQ0dltI9av",
    "outputId": "c3d6aacc-f89b-47fa-d9ae-ddf2b4e1b73e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFTER GM‚ÄôS TAXPAYER BAILOUT AND $10 BILLION IN...</td>\n",
       "      <td>Was the GM bailout REALLY about American jobs?...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Mar 31, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UN NEWS AGENCY SCRUBS TWEET Calling On America...</td>\n",
       "      <td>The United Nations News Centre   the official ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 30, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boiler Room EP #70 ‚Äì Sticks, Stones &amp; The Medi...</td>\n",
       "      <td>Tune in to the Alternate Current Radio Network...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>August 25, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. House Republican gun bill draws the ire o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Republicans in the U.S....</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 1, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KRISPY KREME Worker REFUSES To Serve Cop: ‚Äù I ...</td>\n",
       "      <td>She doesn t  do POlice  until someone threaten...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 6, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  AFTER GM‚ÄôS TAXPAYER BAILOUT AND $10 BILLION IN...   \n",
       "1  UN NEWS AGENCY SCRUBS TWEET Calling On America...   \n",
       "2  Boiler Room EP #70 ‚Äì Sticks, Stones & The Medi...   \n",
       "3  U.S. House Republican gun bill draws the ire o...   \n",
       "4  KRISPY KREME Worker REFUSES To Serve Cop: ‚Äù I ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Was the GM bailout REALLY about American jobs?...      politics   \n",
       "1  The United Nations News Centre   the official ...      politics   \n",
       "2  Tune in to the Alternate Current Radio Network...   Middle-east   \n",
       "3  WASHINGTON (Reuters) - Republicans in the U.S....  politicsNews   \n",
       "4  She doesn t  do POlice  until someone threaten...      politics   \n",
       "\n",
       "              date  label  \n",
       "0     Mar 31, 2016      0  \n",
       "1     Sep 30, 2016      0  \n",
       "2  August 25, 2016      0  \n",
       "3    July 1, 2016       1  \n",
       "4      May 6, 2016      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "true_data = pd.read_csv('/kaggle/input/yai25-toyproject/News _dataset/True.csv')\n",
    "fake_data = pd.read_csv('/kaggle/input/yai25-toyproject/News _dataset/Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "data = pd.concat([true_data, fake_data], ignore_index = True).sample(frac=1).reset_index().drop(columns = ['index'])\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:49.111094Z",
     "iopub.status.busy": "2025-02-20T19:42:49.110713Z",
     "iopub.status.idle": "2025-02-20T19:42:49.882722Z",
     "shell.execute_reply": "2025-02-20T19:42:49.882013Z",
     "shell.execute_reply.started": "2025-02-20T19:42:49.111049Z"
    },
    "id": "fofmHV4uJJOh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer via HuggingFace Transformers\n",
    "bert1 = AutoModel.from_pretrained('bert-base-uncased')\n",
    "bert2 = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:49.884080Z",
     "iopub.status.busy": "2025-02-20T19:42:49.883746Z",
     "iopub.status.idle": "2025-02-20T19:42:49.918313Z",
     "shell.execute_reply": "2025-02-20T19:42:49.917329Z",
     "shell.execute_reply.started": "2025-02-20T19:42:49.884042Z"
    },
    "id": "nw7huw3hJg6B",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train-Validation-Test set split into 70:15:15 ratio about 'text'\n",
    "# Train-Temp split\n",
    "train_text, temp_text, train_text_labels, temp_text_labels = train_test_split(data['text'], data['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=data['label'])\n",
    "# Validation-Test split\n",
    "val_text, test_text, val_text_labels, test_text_labels = train_test_split(temp_text, temp_text_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_text_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:49.919657Z",
     "iopub.status.busy": "2025-02-20T19:42:49.919327Z",
     "iopub.status.idle": "2025-02-20T19:42:49.952200Z",
     "shell.execute_reply": "2025-02-20T19:42:49.951505Z",
     "shell.execute_reply.started": "2025-02-20T19:42:49.919632Z"
    },
    "id": "3AkNIiFEJ15f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train-Validation-Test set split into 70:15:15 ratio about 'title'\n",
    "# Train-Temp split\n",
    "train_title, temp_title, train_title_labels, temp_title_labels = train_test_split(data['title'], data['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=data['label'])\n",
    "# Validation-Test split\n",
    "val_title, test_title, val_title_labels, test_title_labels = train_test_split(temp_title, temp_title_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_title_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:49.953441Z",
     "iopub.status.busy": "2025-02-20T19:42:49.953126Z",
     "iopub.status.idle": "2025-02-20T19:42:49.978859Z",
     "shell.execute_reply": "2025-02-20T19:42:49.977902Z",
     "shell.execute_reply.started": "2025-02-20T19:42:49.953408Z"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1740061827948,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "tGxgjCEbJ3h7",
    "outputId": "23b422f6-5043-46ea-abc5-ac6a40b03308",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44898.000000\n",
       "mean      2469.109693\n",
       "std       2171.617091\n",
       "min          1.000000\n",
       "25%       1234.000000\n",
       "50%       2186.000000\n",
       "75%       3105.000000\n",
       "max      51794.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe data 'text'\n",
    "length = data['text'].apply(len)\n",
    "length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:49.981897Z",
     "iopub.status.busy": "2025-02-20T19:42:49.981639Z",
     "iopub.status.idle": "2025-02-20T19:42:53.159031Z",
     "shell.execute_reply": "2025-02-20T19:42:53.158315Z",
     "shell.execute_reply.started": "2025-02-20T19:42:49.981875Z"
    },
    "id": "Bii_i1xTJ5eH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we set max title length as 64\n",
    "MAX_LENGHT = 64\n",
    "# Tokenize and encode sequences in the train set\n",
    "tokens_title_train = tokenizer.batch_encode_plus(\n",
    "    train_title.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_title_val = tokenizer.batch_encode_plus(\n",
    "    val_title.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_title_test = tokenizer.batch_encode_plus(\n",
    "    test_title.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:53.160900Z",
     "iopub.status.busy": "2025-02-20T19:42:53.160580Z",
     "iopub.status.idle": "2025-02-20T19:42:53.165286Z",
     "shell.execute_reply": "2025-02-20T19:42:53.164357Z",
     "shell.execute_reply.started": "2025-02-20T19:42:53.160869Z"
    },
    "id": "uJAZN_pLJ7UH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_sentences(articles):\n",
    "    \"\"\"Ïó¨Îü¨ Í∞úÏùò Í∏∞ÏÇ¨ÏóêÏÑú Î¨∏Ïû•ÏùÑ Ï∂îÏ∂úÌïòÏó¨ Î¶¨Ïä§Ìä∏Î°ú Î∞òÌôò\"\"\"\n",
    "    sentences = []\n",
    "    for article in articles:\n",
    "        article_sentences = re.split(r'(?<=[.!?]) +', article.strip())  # Î¨∏Ïû• Î∂ÑÌï†\n",
    "        sentences.append(article_sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:53.166587Z",
     "iopub.status.busy": "2025-02-20T19:42:53.166181Z",
     "iopub.status.idle": "2025-02-20T19:42:53.182435Z",
     "shell.execute_reply": "2025-02-20T19:42:53.181778Z",
     "shell.execute_reply.started": "2025-02-20T19:42:53.166558Z"
    },
    "id": "tcRz74Y0J8Ou",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bert_sentence_embedding(sentences):\n",
    "    \"\"\"BERTÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïó¨Îü¨ Î¨∏Ïû•Ïùò CLS Î≤°ÌÑ∞Î•º Ìïú Î≤àÏóê Î∞òÌôò\"\"\"\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # GPU Ïù¥Îèô\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():  # FP16 Í∞ÄÏÜç\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "    cls_vectors = outputs.last_hidden_state[:, 0, :].to(device)  # GPU Ïú†ÏßÄ\n",
    "    return cls_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T19:42:53.183562Z",
     "iopub.status.busy": "2025-02-20T19:42:53.183311Z",
     "iopub.status.idle": "2025-02-20T20:06:45.072924Z",
     "shell.execute_reply": "2025-02-20T20:06:45.071885Z",
     "shell.execute_reply.started": "2025-02-20T19:42:53.183506Z"
    },
    "executionInfo": {
     "elapsed": 935463,
     "status": "ok",
     "timestamp": 1740062778645,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "I6yaKgpLJ9Sv",
    "outputId": "b3453b2e-4e8c-40f2-e216-f5749943fc4e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31428,)\n",
      "count: 0, selected_sentences Length: 0\n",
      "count: 1000, selected_sentences Length: 1000\n",
      "count: 2000, selected_sentences Length: 2000\n",
      "count: 3000, selected_sentences Length: 3000\n",
      "count: 4000, selected_sentences Length: 4000\n",
      "count: 5000, selected_sentences Length: 5000\n",
      "count: 6000, selected_sentences Length: 6000\n",
      "count: 7000, selected_sentences Length: 7000\n",
      "count: 8000, selected_sentences Length: 8000\n",
      "count: 9000, selected_sentences Length: 9000\n",
      "count: 10000, selected_sentences Length: 10000\n",
      "count: 11000, selected_sentences Length: 11000\n",
      "count: 12000, selected_sentences Length: 12000\n",
      "count: 13000, selected_sentences Length: 13000\n",
      "count: 14000, selected_sentences Length: 14000\n",
      "count: 15000, selected_sentences Length: 15000\n",
      "count: 16000, selected_sentences Length: 16000\n",
      "count: 17000, selected_sentences Length: 17000\n",
      "count: 18000, selected_sentences Length: 18000\n",
      "count: 19000, selected_sentences Length: 19000\n",
      "count: 20000, selected_sentences Length: 20000\n",
      "count: 21000, selected_sentences Length: 21000\n",
      "count: 22000, selected_sentences Length: 22000\n",
      "count: 23000, selected_sentences Length: 23000\n",
      "count: 24000, selected_sentences Length: 24000\n",
      "count: 25000, selected_sentences Length: 25000\n",
      "count: 26000, selected_sentences Length: 26000\n",
      "count: 27000, selected_sentences Length: 27000\n",
      "count: 28000, selected_sentences Length: 28000\n",
      "count: 29000, selected_sentences Length: 29000\n",
      "count: 30000, selected_sentences Length: 30000\n",
      "count: 31000, selected_sentences Length: 31000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# BERT Î™®Îç∏ Load\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device).eval()  # ÌèâÍ∞Ä Î™®Îìú\n",
    "\n",
    "# Ï†êÏàò Í≥ÑÏÇ∞ Î∞è ÌïµÏã¨ Î¨∏Ïû• ÏÑ†ÌÉù Ìï®Ïàò\n",
    "def score(articles, n=3, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    \"\"\"\n",
    "    Í∞Å Í∏∞ÏÇ¨ÏóêÏÑú Í∞ÄÏû• Ï§ëÏöîÌïú Î¨∏Ïû•ÏùÑ HeadlineÏúºÎ°ú ÏÑ†Ï†ï\n",
    "    Í∞Å Î¨∏Ïû•Í≥º HeadlineÏùò Ïú†ÏÇ¨ÎèÑÎ•º Í≥ÑÏÇ∞ ÌõÑ ÏÉÅÏúÑ nÍ∞ú Î¨∏Ïû• ÏÑ†ÌÉù\n",
    "    \"\"\"\n",
    "    selected_sentences = []\n",
    "    all_articles_sentences = extract_sentences(articles)  # Í∏∞ÏÇ¨Î≥Ñ Î¨∏Ïû• Î¶¨Ïä§Ìä∏\n",
    "    count = 0\n",
    "    for sentences in all_articles_sentences:\n",
    "        if count % 1000 == 0:\n",
    "            print(\"count: {}, selected_sentences Length: {}\".format(count, len(selected_sentences)))\n",
    "\n",
    "        if len(sentences) < 3:  # Î¨∏Ïû•Ïùò Í∏∏Ïù¥Í∞Ä 3Î≥¥Îã§ ÏûëÏúºÎ©¥ Ìï¥Îãπ Î¨∏Ïû•ÏùÑ Î™®Îëê ÎÑ£Ïñ¥Í∏∞Í∏∞\n",
    "            selected_sentences.append(sentences)\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # üîπ Headline ÏÑ†Ï†ï (TF-IDF Í∏∞Ï§Ä)\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        headline_idx = np.argmax(tfidf_matrix.sum(axis=1))  # TF-IDF Ï†êÏàò ÏµúÎåÄ Î¨∏Ïû•(doc) ÏÑ†ÌÉù\n",
    "        headline = sentences[headline_idx]\n",
    "\n",
    "        # üîπ Î¨∏Ïû• ÏûÑÎ≤†Îî© Í≥ÑÏÇ∞ (Batch Ï≤òÎ¶¨)\n",
    "        sentence_embeddings = bert_sentence_embedding(sentences)  # GPU ÌÖêÏÑú\n",
    "        headline_embedding = bert_sentence_embedding([headline])  # GPU ÌÖêÏÑú\n",
    "\n",
    "        # üîπ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞\n",
    "        rel_scores = torch.nn.functional.cosine_similarity(sentence_embeddings, headline_embedding)\n",
    "\n",
    "        # üîπ TF-IDF Ï†êÏàò (GPU Î≥ÄÌôò)\n",
    "        sentence_tfidf = torch.tensor(tfidf_matrix.sum(axis=1)).float().squeeze().to(device)\n",
    "\n",
    "        # üîπ Î¨∏Ïû• ÏúÑÏπò Ï†êÏàò (GPU Î≥ÄÌôò)\n",
    "        position_scores = torch.tensor(1.0 / (np.arange(1, len(sentences) + 1)), dtype=torch.float32).to(device)\n",
    "\n",
    "        # üîπ ÏµúÏ¢Ö Ï†êÏàò Í≥ÑÏÇ∞\n",
    "        worth_scores = alpha * rel_scores + beta * sentence_tfidf + gamma * position_scores\n",
    "        top_indices = torch.topk(worth_scores, n).indices.cpu().tolist()  # GPU ‚Üí CPU Î≥ÄÌôò ÌõÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "\n",
    "        selected_sentences.append([sentences[i] for i in top_indices])  # ÏµúÏ¢Ö ÏÑ†ÌÉùÎêú Î¨∏Ïû• Ï†ÄÏû•\n",
    "        count += 1\n",
    "\n",
    "    return selected_sentences\n",
    "\n",
    "articles = train_text.tolist()\n",
    "print(np.shape(articles))\n",
    "\n",
    "with torch.cuda.amp.autocast():  # FP16 Í∞ÄÏÜç\n",
    "    result = score(articles, n=3)\n",
    "\n",
    "train_top_text = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:06:45.074558Z",
     "iopub.status.busy": "2025-02-20T20:06:45.074168Z",
     "iopub.status.idle": "2025-02-20T20:11:50.140316Z",
     "shell.execute_reply": "2025-02-20T20:11:50.139615Z",
     "shell.execute_reply.started": "2025-02-20T20:06:45.074509Z"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "error",
     "timestamp": 1740064417419,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "H5APFVloJ-GX",
    "outputId": "eb584a5c-c6c5-4715-a9ae-5410c9a7ba1a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6735,)\n",
      "count: 0, selected_sentences Length: 0\n",
      "count: 1000, selected_sentences Length: 1000\n",
      "count: 2000, selected_sentences Length: 2000\n",
      "count: 3000, selected_sentences Length: 3000\n",
      "count: 4000, selected_sentences Length: 4000\n",
      "count: 5000, selected_sentences Length: 5000\n",
      "count: 6000, selected_sentences Length: 6000\n"
     ]
    }
   ],
   "source": [
    "articles = val_text.tolist()\n",
    "print(np.shape(articles))\n",
    "\n",
    "with torch.cuda.amp.autocast():  # FP16 Í∞ÄÏÜç\n",
    "    result = score(articles, n=3)\n",
    "\n",
    "val_top_text = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:11:50.141476Z",
     "iopub.status.busy": "2025-02-20T20:11:50.141203Z",
     "iopub.status.idle": "2025-02-20T20:16:56.432414Z",
     "shell.execute_reply": "2025-02-20T20:16:56.431669Z",
     "shell.execute_reply.started": "2025-02-20T20:11:50.141448Z"
    },
    "executionInfo": {
     "elapsed": 196248,
     "status": "ok",
     "timestamp": 1740063171834,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "sI0VWnfYMs1v",
    "outputId": "6f9cc34d-26c8-4d48-fea4-52499686a884",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6735,)\n",
      "count: 0, selected_sentences Length: 0\n",
      "count: 1000, selected_sentences Length: 1000\n",
      "count: 2000, selected_sentences Length: 2000\n",
      "count: 3000, selected_sentences Length: 3000\n",
      "count: 4000, selected_sentences Length: 4000\n",
      "count: 5000, selected_sentences Length: 5000\n",
      "count: 6000, selected_sentences Length: 6000\n"
     ]
    }
   ],
   "source": [
    "articles = test_text.tolist()\n",
    "print(np.shape(articles))\n",
    "\n",
    "with torch.cuda.amp.autocast():  # FP16 Í∞ÄÏÜç\n",
    "    result = score(articles, n=3)\n",
    "\n",
    "test_top_text = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:56.433568Z",
     "iopub.status.busy": "2025-02-20T20:16:56.433261Z",
     "iopub.status.idle": "2025-02-20T20:16:57.209988Z",
     "shell.execute_reply": "2025-02-20T20:16:57.209071Z",
     "shell.execute_reply.started": "2025-02-20T20:16:56.433536Z"
    },
    "executionInfo": {
     "elapsed": 1547,
     "status": "ok",
     "timestamp": 1740063173417,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "2Te4JwhrMtl-",
    "outputId": "4a09d2d0-001c-45d8-ea4e-b01c664ea3b8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31428,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "copy = copy.deepcopy(train_top_text)\n",
    "copy = [\" \".join(sublist) for sublist in copy]\n",
    "np.shape(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:57.211252Z",
     "iopub.status.busy": "2025-02-20T20:16:57.210952Z",
     "iopub.status.idle": "2025-02-20T20:16:58.501403Z",
     "shell.execute_reply": "2025-02-20T20:16:58.500659Z",
     "shell.execute_reply.started": "2025-02-20T20:16:57.211222Z"
    },
    "executionInfo": {
     "elapsed": 2736,
     "status": "ok",
     "timestamp": 1740065309854,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "Y6WNBu-LPLct",
    "outputId": "14e0d711-74e8-4667-d737-3f50ba9ed5ab",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (31428,), Validation shape: (6735,), Test shape: (6735,)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "train_copy_text = copy.deepcopy(train_top_text)\n",
    "train_copy_text = [\" \".join(sublist) for sublist in train_copy_text]\n",
    "val_copy_text = copy.deepcopy(val_top_text)\n",
    "val_copy_text = [\" \".join(sublist) for sublist in val_copy_text]\n",
    "test_copy_text = copy.deepcopy(test_top_text)\n",
    "test_copy_text = [\" \".join(sublist) for sublist in test_copy_text]\n",
    "print(\"Train shape: {}, Validation shape: {}, Test shape: {}\".format(np.shape(train_copy_text), np.shape(val_copy_text),\n",
    "                                                                    np.shape(test_copy_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:58.502562Z",
     "iopub.status.busy": "2025-02-20T20:16:58.502219Z",
     "iopub.status.idle": "2025-02-20T20:16:58.508583Z",
     "shell.execute_reply": "2025-02-20T20:16:58.507887Z",
     "shell.execute_reply.started": "2025-02-20T20:16:58.502507Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740065311597,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "lP5Ab75n2laf",
    "outputId": "2fe46988-9915-4af3-c897-5556ce2f317e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def save_list_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    Î¶¨Ïä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î•º CSV ÌååÏùºÎ°ú Ï†ÄÏû•ÌïòÎäî Ìï®Ïàò\n",
    "\n",
    "    :param data: Î¶¨Ïä§Ìä∏ (Í∞Å ÏöîÏÜåÍ∞Ä Î¨∏Ïû•Ïù¥Ïñ¥Ïïº Ìï®)\n",
    "    :param filename: Ï†ÄÏû•Ìï† CSV ÌååÏùº Ïù¥Î¶Ñ (Ïòà: 'output.csv')\n",
    "    \"\"\"\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in data:\n",
    "            writer.writerow([row])  # Î¨∏ÏûêÏó¥ÏùÑ ÌïòÎÇòÏùò Ïª¨ÎüºÏúºÎ°ú Ï†ÄÏû•\n",
    "\n",
    "# ÏÇ¨Ïö© ÏòàÏãú\n",
    "data = [\n",
    "    \"Hello world, this is a test.\",\n",
    "    \"Python is great for data processing!\",\n",
    "    \"CSV files are easy to handle.\"\n",
    "]\n",
    "\n",
    "save_list_to_csv(data, \"output.csv\")\n",
    "print(\"CSV ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:58.509584Z",
     "iopub.status.busy": "2025-02-20T20:16:58.509358Z",
     "iopub.status.idle": "2025-02-20T20:16:59.070473Z",
     "shell.execute_reply": "2025-02-20T20:16:59.069800Z",
     "shell.execute_reply.started": "2025-02-20T20:16:58.509564Z"
    },
    "id": "SP7flDEf2mJT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_list_to_csv(train_copy_text, \"/kaggle/working/train_copy_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:59.071458Z",
     "iopub.status.busy": "2025-02-20T20:16:59.071226Z",
     "iopub.status.idle": "2025-02-20T20:16:59.310192Z",
     "shell.execute_reply": "2025-02-20T20:16:59.309246Z",
     "shell.execute_reply.started": "2025-02-20T20:16:59.071437Z"
    },
    "id": "uEGmQiUU2txm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_list_to_csv(val_copy_text, \"/kaggle/working/val_copy_text.csv\")\n",
    "save_list_to_csv(test_copy_text, \"/kaggle/working/test_copy_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:59.311388Z",
     "iopub.status.busy": "2025-02-20T20:16:59.311149Z",
     "iopub.status.idle": "2025-02-20T20:16:59.317667Z",
     "shell.execute_reply": "2025-02-20T20:16:59.316717Z",
     "shell.execute_reply.started": "2025-02-20T20:16:59.311366Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1740065190714,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "gVMqL7ZT5LLu",
    "outputId": "1aaa1bdb-ec65-454e-9d3a-ba4486927a96",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ÌååÏùºÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò:\n",
      "Hello world, this is a test.\n",
      "Python is great for data processing!\n",
      "CSV files are easy to handle.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_csv_to_list(filename):\n",
    "    \"\"\"\n",
    "    CSV ÌååÏùºÏùÑ ÏùΩÏñ¥ÏÑú Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò\n",
    "\n",
    "    :param filename: ÏùΩÏùÑ CSV ÌååÏùº Ïù¥Î¶Ñ\n",
    "    :return: Î¶¨Ïä§Ìä∏ (Í∞Å ÌñâÏù¥ ÌïòÎÇòÏùò Î¨∏Ïû•ÏúºÎ°ú Ï†ÄÏû•Îê®)\n",
    "    \"\"\"\n",
    "    with open(filename, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [row[0] for row in reader]  # Ï≤´ Î≤àÏß∏ Ïó¥Îßå Î¶¨Ïä§Ìä∏Î°ú Ï†ÄÏû•\n",
    "    return data\n",
    "\n",
    "# ÏÇ¨Ïö© ÏòàÏãú\n",
    "filename = \"output.csv\"\n",
    "loaded_data = load_csv_to_list(filename)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"CSV ÌååÏùºÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò:\")\n",
    "for row in loaded_data:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:59.318880Z",
     "iopub.status.busy": "2025-02-20T20:16:59.318607Z",
     "iopub.status.idle": "2025-02-20T20:16:59.830341Z",
     "shell.execute_reply": "2025-02-20T20:16:59.829610Z",
     "shell.execute_reply.started": "2025-02-20T20:16:59.318848Z"
    },
    "id": "8tYcdTUA-Ifw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_copy_text = load_csv_to_list(\"/kaggle/working/train_copy_text.csv\")\n",
    "val_copy_text = load_csv_to_list(\"/kaggle/working/val_copy_text.csv\")\n",
    "test_copy_text = load_csv_to_list(\"/kaggle/working/test_copy_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:16:59.831552Z",
     "iopub.status.busy": "2025-02-20T20:16:59.831277Z",
     "iopub.status.idle": "2025-02-20T20:17:13.956049Z",
     "shell.execute_reply": "2025-02-20T20:17:13.955342Z",
     "shell.execute_reply.started": "2025-02-20T20:16:59.831493Z"
    },
    "id": "lpqUJ1TePM4U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we set max text length as 512\n",
    "MAX_LENGHT = 512\n",
    "# Tokenize and encode sequences in the train set\n",
    "tokens_text_train = tokenizer.batch_encode_plus(\n",
    "    train_copy_text,\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_text_val = tokenizer.batch_encode_plus(\n",
    "    val_copy_text,\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_text_test = tokenizer.batch_encode_plus(\n",
    "    test_copy_text,\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:13.957174Z",
     "iopub.status.busy": "2025-02-20T20:17:13.956890Z",
     "iopub.status.idle": "2025-02-20T20:17:14.876590Z",
     "shell.execute_reply": "2025-02-20T20:17:14.875715Z",
     "shell.execute_reply.started": "2025-02-20T20:17:13.957146Z"
    },
    "id": "VRiueaPcPNqT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert lists to tensors\n",
    "train_title_seq = torch.tensor(tokens_title_train['input_ids'])\n",
    "train_title_mask = torch.tensor(tokens_title_train['attention_mask'])\n",
    "train_title_y = torch.tensor(train_title_labels.tolist())\n",
    "\n",
    "val_title_seq = torch.tensor(tokens_title_val['input_ids'])\n",
    "val_title_mask = torch.tensor(tokens_title_val['attention_mask'])\n",
    "val_title_y = torch.tensor(val_title_labels.tolist())\n",
    "\n",
    "test_title_seq = torch.tensor(tokens_title_test['input_ids'])\n",
    "test_title_mask = torch.tensor(tokens_title_test['attention_mask'])\n",
    "test_title_y = torch.tensor(test_title_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:14.880129Z",
     "iopub.status.busy": "2025-02-20T20:17:14.879893Z",
     "iopub.status.idle": "2025-02-20T20:17:21.820170Z",
     "shell.execute_reply": "2025-02-20T20:17:21.819232Z",
     "shell.execute_reply.started": "2025-02-20T20:17:14.880109Z"
    },
    "id": "oo_h6va2POZr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert lists to tensors\n",
    "train_text_seq = torch.tensor(tokens_text_train['input_ids'])\n",
    "train_text_mask = torch.tensor(tokens_text_train['attention_mask'])\n",
    "train_text_y = torch.tensor(train_text_labels.tolist())\n",
    "\n",
    "val_text_seq = torch.tensor(tokens_text_val['input_ids'])\n",
    "val_text_mask = torch.tensor(tokens_text_val['attention_mask'])\n",
    "val_text_y = torch.tensor(val_text_labels.tolist())\n",
    "\n",
    "test_text_seq = torch.tensor(tokens_text_test['input_ids'])\n",
    "test_text_mask = torch.tensor(tokens_text_test['attention_mask'])\n",
    "test_text_y = torch.tensor(test_text_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:21.821920Z",
     "iopub.status.busy": "2025-02-20T20:17:21.821610Z",
     "iopub.status.idle": "2025-02-20T20:17:21.827015Z",
     "shell.execute_reply": "2025-02-20T20:17:21.826073Z",
     "shell.execute_reply.started": "2025-02-20T20:17:21.821890Z"
    },
    "id": "82WHBhowPO90",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Loader structure definition\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32                                               #define a batch size\n",
    "\n",
    "train_title_data = TensorDataset(train_title_seq, train_title_mask, train_title_y)    # wrap tensors\n",
    "train_title_sampler = RandomSampler(train_title_data)                     # sampler for sampling the data during training\n",
    "train_title_dataloader = DataLoader(train_title_data, sampler=train_title_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for train set\n",
    "val_title_data = TensorDataset(val_title_seq, val_title_mask, val_title_y)            # wrap tensors\n",
    "val_title_sampler = SequentialSampler(val_title_data)                     # sampler for sampling the data during training\n",
    "val_title_dataloader = DataLoader(val_title_data, sampler = val_title_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:21.828088Z",
     "iopub.status.busy": "2025-02-20T20:17:21.827822Z",
     "iopub.status.idle": "2025-02-20T20:17:21.850104Z",
     "shell.execute_reply": "2025-02-20T20:17:21.849429Z",
     "shell.execute_reply.started": "2025-02-20T20:17:21.828067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([31428, 512]), torch.Size([31428, 512]), torch.Size([31428, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_seq.shape, train_text_mask.shape, train_text_y.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:21.851190Z",
     "iopub.status.busy": "2025-02-20T20:17:21.850893Z",
     "iopub.status.idle": "2025-02-20T20:17:21.866243Z",
     "shell.execute_reply": "2025-02-20T20:17:21.865592Z",
     "shell.execute_reply.started": "2025-02-20T20:17:21.851156Z"
    },
    "id": "--Qkh3USPUBk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Loader structure definition\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32                                               #define a batch size\n",
    "\n",
    "train_text_data = TensorDataset(train_text_seq, train_text_mask, train_text_y.reshape(-1, 1))    # wrap tensors\n",
    "train_text_sampler = RandomSampler(train_text_data)                     # sampler for sampling the data during training\n",
    "train_text_dataloader = DataLoader(train_text_data, sampler=train_text_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for train set\n",
    "val_text_data = TensorDataset(val_text_seq, val_text_mask, val_text_y)            # wrap tensors\n",
    "val_text_sampler = SequentialSampler(val_text_data)                     # sampler for sampling the data during training\n",
    "val_text_dataloader = DataLoader(val_text_data, sampler = val_text_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:21.867329Z",
     "iopub.status.busy": "2025-02-20T20:17:21.866944Z",
     "iopub.status.idle": "2025-02-20T20:17:22.198274Z",
     "shell.execute_reply": "2025-02-20T20:17:22.197614Z",
     "shell.execute_reply.started": "2025-02-20T20:17:21.867301Z"
    },
    "id": "ysaBj8HGPW3G",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert1, bert2):\n",
    "      super(BERT_Arch, self).__init__()\n",
    "      self.bert1 = bert1\n",
    "      self.bert2 = bert2\n",
    "      self.dropout = nn.Dropout(0.1)            # dropout layer\n",
    "      self.relu =  nn.ReLU()                    # relu activation function\n",
    "      self.fc1 = nn.Linear(1536,768)             # dense layer 1\n",
    "      self.fc2 = nn.Linear(768,2)              # dense layer 2 (Output layer)\n",
    "      self.softmax = nn.LogSoftmax(dim=1)       # softmax activation function\n",
    "\n",
    "    def forward(self, sent_id1, mask1, sent_id2, mask2):           # define the forward pass\n",
    "      cls_hs = self.bert1(sent_id1, attention_mask=mask1)['pooler_output'] # headline\n",
    "      cls_text = self.bert2(sent_id2, attention_mask=mask2)['pooler_output']\n",
    "      cls = torch.concat((cls_hs, cls_text), dim = 1).to(device)\n",
    "\n",
    "      x = self.fc1(cls)                         # pass the inputs to the model\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc2(x)                           # output layer\n",
    "      x = self.softmax(x)                       # apply softmax activation\n",
    "      return x\n",
    "\n",
    "model = BERT_Arch(bert1, bert2).to(device)\n",
    "# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n",
    "# Define the optimizer\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          # learning rate\n",
    "# Define the loss function\n",
    "cross_entropy  = nn.NLLLoss().to(device)\n",
    "# Number of training epochs\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T20:17:22.199259Z",
     "iopub.status.busy": "2025-02-20T20:17:22.199059Z",
     "iopub.status.idle": "2025-02-20T20:17:22.209754Z",
     "shell.execute_reply": "2025-02-20T20:17:22.208842Z",
     "shell.execute_reply.started": "2025-02-20T20:17:22.199240Z"
    },
    "id": "q0myX9hLPYFF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining training and evaluation functions\n",
    "def train(train_title_dataloader, train_text_dataloader):\n",
    "  model.train()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "\n",
    "  for step, (batch1, batch2) in enumerate(zip(train_title_dataloader, train_text_dataloader)):                # iterate over batches\n",
    "    if step % 50 == 0 and not step == 0:                        # progress update after every 50 batches.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_title_dataloader)))\n",
    "    #batch = [r for r in batch]                                  # push the batch to gpu\n",
    "    sent_id1, mask1, labels1 = batch1\n",
    "    sent_id1 = sent_id1.to(device)\n",
    "    mask1 = mask1.to(device)\n",
    "    labels1 = labels1.to(device)\n",
    "\n",
    "    sent_id2, mask2, labels2 = batch2\n",
    "    sent_id2 = sent_id2.to(device)\n",
    "    mask2 = mask2.to(device)\n",
    "    labels2 = labels2.to(device) # label1 == label2 : True\n",
    "\n",
    "    model.zero_grad()                                           # clear previously calculated gradients\n",
    "    preds = model(sent_id1, mask1, sent_id2, mask2).to(device)             # get model predictions for current batch\n",
    "    loss = cross_entropy(preds, labels1)                         # compute loss between actual & predicted values\n",
    "    total_loss = total_loss + loss.item()                       # add on to the total loss\n",
    "    loss.backward()                                             # backward pass to calculate the gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
    "    optimizer.step()                                            # update parameters\n",
    "    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n",
    "\n",
    "  avg_loss = total_loss / len(train_title_dataloader)                 # compute training loss of the epoch\n",
    "                                                                # reshape predictions in form of (# samples, # classes)\n",
    "  return avg_loss                                 # returns the loss and predictions\n",
    "\n",
    "def evaluate(val_title_dataloader, val_text_dataloader):\n",
    "  print(\"\\nEvaluating...\")\n",
    "  model.eval()                                    # Deactivate dropout layers\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  for step, (batch1, batch2) in enumerate(zip(val_title_dataloader, val_text_dataloader)):    # Iterate over batches\n",
    "    if step % 50 == 0 and not step == 0:          # Progress update every 50 batches.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_title_dataloader)))\n",
    "                                                  # Report progress\n",
    "    #batch = [t for t in batch]                    # Push the batch to GPU\n",
    "\n",
    "    sent_id1, mask1, labels1 = batch1\n",
    "    sent_id1 = sent_id1.to(device)\n",
    "    mask1 = mask1.to(device)\n",
    "    labels1 = labels1.to(device)\n",
    "\n",
    "    sent_id2, mask2, labels2 = batch2\n",
    "    sent_id2 = sent_id2.to(device)\n",
    "    mask2 = mask2.to(device)\n",
    "    labels2 = labels2.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():                         # Deactivate autograd\n",
    "      preds = model(sent_id1, mask1, sent_id2, mask2).to(device)                # Model predictions\n",
    "      loss = cross_entropy(preds, labels1)          # Compute the validation loss between actual and predicted values\n",
    "      total_loss = total_loss + loss.item()\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "  avg_loss = total_loss / len(val_title_dataloader)         # compute the validation loss of the epoch\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model fine-tuning??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T20:26:53.988124Z",
     "iopub.status.busy": "2025-02-20T20:26:53.987830Z",
     "iopub.status.idle": "2025-02-20T21:31:45.828643Z",
     "shell.execute_reply": "2025-02-20T21:31:45.827672Z",
     "shell.execute_reply.started": "2025-02-20T20:26:53.988101Z"
    },
    "executionInfo": {
     "elapsed": 7237990,
     "status": "ok",
     "timestamp": 1740060626683,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "HzFwzUgMPZL-",
    "outputId": "85634acd-dfb1-4f30-b058-76294111b963",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 2\n",
      "  Batch    50  of    983.\n",
      "  Batch   100  of    983.\n",
      "  Batch   150  of    983.\n",
      "  Batch   200  of    983.\n",
      "  Batch   250  of    983.\n",
      "  Batch   300  of    983.\n",
      "  Batch   350  of    983.\n",
      "  Batch   400  of    983.\n",
      "  Batch   450  of    983.\n",
      "  Batch   500  of    983.\n",
      "  Batch   550  of    983.\n",
      "  Batch   600  of    983.\n",
      "  Batch   650  of    983.\n",
      "  Batch   700  of    983.\n",
      "  Batch   750  of    983.\n",
      "  Batch   800  of    983.\n",
      "  Batch   850  of    983.\n",
      "  Batch   900  of    983.\n",
      "  Batch   950  of    983.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    211.\n",
      "  Batch   100  of    211.\n",
      "  Batch   150  of    211.\n",
      "  Batch   200  of    211.\n",
      "\n",
      "Training Loss: 0.073\n",
      "Validation Loss: 0.053\n",
      "\n",
      " Epoch 2 / 2\n",
      "  Batch    50  of    983.\n",
      "  Batch   100  of    983.\n",
      "  Batch   150  of    983.\n",
      "  Batch   200  of    983.\n",
      "  Batch   250  of    983.\n",
      "  Batch   300  of    983.\n",
      "  Batch   350  of    983.\n",
      "  Batch   400  of    983.\n",
      "  Batch   450  of    983.\n",
      "  Batch   500  of    983.\n",
      "  Batch   550  of    983.\n",
      "  Batch   600  of    983.\n",
      "  Batch   650  of    983.\n",
      "  Batch   700  of    983.\n",
      "  Batch   750  of    983.\n",
      "  Batch   800  of    983.\n",
      "  Batch   850  of    983.\n",
      "  Batch   900  of    983.\n",
      "  Batch   950  of    983.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    211.\n",
      "  Batch   100  of    211.\n",
      "  Batch   150  of    211.\n",
      "  Batch   200  of    211.\n",
      "\n",
      "Training Loss: 0.035\n",
      "Validation Loss: 0.055\n"
     ]
    }
   ],
   "source": [
    "# Train and predict\n",
    "# Head line\n",
    "best_valid_loss = float('inf')\n",
    "train_losses=[]                   # empty lists to store training and validation loss of each epoch\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    train_loss = train(train_title_dataloader, train_text_dataloader) # train model\n",
    "    valid_loss = evaluate(val_title_dataloader, val_text_dataloader)  # evaluate model\n",
    "    if valid_loss < best_valid_loss:              # save the best model\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '/kaggle/working/c1_dual_bert_model_weights.pt')\n",
    "    train_losses.append(train_loss)               # append training and validation loss\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T21:31:45.830438Z",
     "iopub.status.busy": "2025-02-20T21:31:45.830053Z",
     "iopub.status.idle": "2025-02-20T21:31:46.528577Z",
     "shell.execute_reply": "2025-02-20T21:31:46.527607Z",
     "shell.execute_reply.started": "2025-02-20T21:31:45.830403Z"
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1740063499470,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "K5Nd-3luuF2A",
    "outputId": "35ff7063-8900-463a-f2f0-6d0e5207429f",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights of best model\n",
    "path = '/kaggle/working/c1_dual_bert_model_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T21:31:46.530665Z",
     "iopub.status.busy": "2025-02-20T21:31:46.530396Z",
     "iopub.status.idle": "2025-02-20T21:31:48.031360Z",
     "shell.execute_reply": "2025-02-20T21:31:48.030604Z",
     "shell.execute_reply.started": "2025-02-20T21:31:46.530643Z"
    },
    "id": "xfhQALsb41QS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T21:31:48.033768Z",
     "iopub.status.busy": "2025-02-20T21:31:48.033407Z",
     "iopub.status.idle": "2025-02-20T21:31:48.040096Z",
     "shell.execute_reply": "2025-02-20T21:31:48.039359Z",
     "shell.execute_reply.started": "2025-02-20T21:31:48.033738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6735, 31428, 6735)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_copy_text), len(train_copy_text), len(val_copy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T21:31:48.041267Z",
     "iopub.status.busy": "2025-02-20T21:31:48.040996Z",
     "iopub.status.idle": "2025-02-20T21:31:48.062452Z",
     "shell.execute_reply": "2025-02-20T21:31:48.061611Z",
     "shell.execute_reply.started": "2025-02-20T21:31:48.041245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6735, 6735, 6735, 6735, 6735)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_title_seq), len(test_title_mask), len(test_text_seq), len(test_text_mask), len(test_title_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:13:23.758015Z",
     "iopub.status.busy": "2025-02-20T22:13:23.757684Z",
     "iopub.status.idle": "2025-02-20T22:15:14.945312Z",
     "shell.execute_reply": "2025-02-20T22:15:14.944387Z",
     "shell.execute_reply.started": "2025-02-20T22:13:23.757986Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3523\n",
      "           1       0.99      0.98      0.98      3212\n",
      "\n",
      "    accuracy                           0.99      6735\n",
      "   macro avg       0.99      0.98      0.98      6735\n",
      "weighted avg       0.99      0.99      0.99      6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8  # GPU Î©îÎ™®Î¶¨ ÏÉÅÌô©Ïóê Îî∞Îùº Ï†ÅÏ†àÌïú Î∞∞Ïπò ÌÅ¨Í∏∞Î°ú Ï°∞Ï†ï\n",
    "preds_list = []\n",
    "\n",
    "model.eval()  # ÌèâÍ∞Ä Î™®ÎìúÎ°ú Ï†ÑÌôò\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_title_seq), batch_size):\n",
    "        # Î∞∞Ïπò Îã®ÏúÑÎ°ú Îç∞Ïù¥ÌÑ∞Î•º ÏÑ†ÌÉùÌïòÍ≥† GPUÎ°ú Ïù¥Îèô\n",
    "        batch_title_seq = test_title_seq[i:i+batch_size].to(device)\n",
    "        batch_title_mask = test_title_mask[i:i+batch_size].to(device)\n",
    "        batch_text_seq = test_text_seq[i:i+batch_size].to(device)\n",
    "        batch_text_mask = test_text_mask[i:i+batch_size].to(device)\n",
    "        \n",
    "        # Î™®Îç∏ Ï∂îÎ°†\n",
    "        batch_preds = model(batch_title_seq, batch_title_mask, batch_text_seq, batch_text_mask)\n",
    "        preds_list.append(batch_preds.detach().cpu().numpy())\n",
    "\n",
    "# Î™®Îì† Î∞∞ÏπòÏùò Í≤∞Í≥º Ïó∞Í≤∞\n",
    "preds = np.concatenate(preds_list, axis=0)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print(classification_report(test_title_y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:23:45.534079Z",
     "iopub.status.busy": "2025-02-20T22:23:45.533780Z",
     "iopub.status.idle": "2025-02-20T22:23:45.548716Z",
     "shell.execute_reply": "2025-02-20T22:23:45.547842Z",
     "shell.execute_reply.started": "2025-02-20T22:23:45.534057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98498   0.98638   0.98568      3523\n",
      "           1    0.98503   0.98350   0.98427      3212\n",
      "\n",
      "    accuracy                        0.98500      6735\n",
      "   macro avg    0.98501   0.98494   0.98497      6735\n",
      "weighted avg    0.98500   0.98500   0.98500      6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_title_y, preds, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "execution": {
     "iopub.execute_input": "2025-02-20T22:19:51.414700Z",
     "iopub.status.busy": "2025-02-20T22:19:51.414371Z",
     "iopub.status.idle": "2025-02-20T22:19:51.418390Z",
     "shell.execute_reply": "2025-02-20T22:19:51.417445Z",
     "shell.execute_reply.started": "2025-02-20T22:19:51.414673Z"
    },
    "executionInfo": {
     "elapsed": 1568,
     "status": "error",
     "timestamp": 1740064265071,
     "user": {
      "displayName": "ÏñëÎØºÏÑù(Ïù¥Í≥ºÎåÄÌïô ÏàòÌïô)",
      "userId": "02271415178336658648"
     },
     "user_tz": -540
    },
    "id": "6tzLPApnPaOt",
    "outputId": "a774d4c0-936e-40ee-e180-e3f6181c4fb8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#   test_title_seq = test_title_seq.to(device)\n",
    "#   test_title_mask = test_title_mask.to(device)\n",
    "#   test_text_seq = test_text_seq.to(device)\n",
    "#   test_text_mask = test_text_mask.to(device)\n",
    "#   preds = model(test_title_seq, test_title_mask, test_text_seq, test_text_mask)\n",
    "#   preds = preds.detach().cpu().numpy()\n",
    "\n",
    "# preds = np.argmax(preds, axis = 1)\n",
    "# print(classification_report(test_title_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMPVpNKZsBCkK8jgdXOSl94",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6708049,
     "sourceId": 10806821,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6696311,
     "sourceId": 10807123,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
